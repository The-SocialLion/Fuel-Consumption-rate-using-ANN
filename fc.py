# -*- coding: utf-8 -*-
"""FC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZfHN2zwYuzidvxkEHnHvKZOJjoWIE-8T
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd

df=pd.read_csv('emissions.csv')
df=df.dropna(how='any')
id=df['id']
df=df.drop(columns=['efid','id'])
df

df['scoreAlt'].unique()

df['smartwayScore'].unique()

df['standard'].unique()

df['stdText'].unique()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['standard']=le.fit_transform(df['standard'])
df['stdText']=le.fit_transform(df['stdText'])

from sklearn.preprocessing import LabelEncoder
le1=LabelEncoder()
df['scoreAlt']=le1.fit_transform(df['scoreAlt'])
df['smartwayScore']=le1.fit_transform(df['smartwayScore'])

df['standard'].unique()

df['stdText'].unique()

df

X=df.iloc[:,:-2].values
y=df.iloc[:,-2].values
z=df.iloc[:,-1].values

X

y

z

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.25 ,random_state = 1)

from sklearn.model_selection import train_test_split
X_train1, X_test1, z_train,z_test = train_test_split(X, z, test_size = 0.25 ,random_state = 1)

y_train=tf.keras.utils.to_categorical(y_train)
y_test=tf.keras.utils.to_categorical(y_test)
z_train=tf.keras.utils.to_categorical(z_train)
z_test=tf.keras.utils.to_categorical(z_test)

ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=50,activation='relu'))
ann.add(tf.keras.layers.Dense(units=100,activation='relu'))
ann.add(tf.keras.layers.Dense(units=150,activation='relu'))
ann.add(tf.keras.layers.Dense(units=200,activation='relu'))
ann.add(tf.keras.layers.Dense(units=46,activation='softmax'))

ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = ann.fit(X_train, y_train, batch_size=15, epochs=100,validation_data=(X_test, y_test))
ann.save("FC.h5")

ann1 = tf.keras.models.Sequential()
ann1.add(tf.keras.layers.Dense(units=50,activation='relu'))
ann1.add(tf.keras.layers.Dense(units=100,activation='relu'))
ann1.add(tf.keras.layers.Dense(units=150,activation='relu'))
ann1.add(tf.keras.layers.Dense(units=200,activation='relu'))
ann1.add(tf.keras.layers.Dense(units=50,activation='softmax'))

ann1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history1 = ann1.fit(X_train1, z_train, batch_size=15, epochs=100,validation_data=(X_test1, z_test))
ann1.save("FC1.h5")

plt.figure(0)
plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.title('Results for ANN training-1')
plt.savefig('Accuracy.png')

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.title('Results for ANN training-1')
plt.savefig('Loss.png')

plt.figure(2)
plt.plot(history1.history['accuracy'], label='training accuracy')
plt.plot(history1.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.title('Results for ANN training-2')
plt.savefig('Accuracy.png')

plt.figure(3)
plt.plot(history1.history['loss'], label='training loss')
plt.plot(history1.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.title('Results for ANN training-2')
plt.savefig('Loss.png')

print("Saved Model & Graph to disk")

model = tf.keras.models.load_model('FC.h5')
model1= tf.keras.models.load_model('FC1.h5')
print("Loaded model from disk")

z_pred=model1.predict(X_test)
z_pred=np.round(z_pred)
np.set_printoptions(precision=2)
print(z_pred)

from sklearn.metrics import accuracy_score
print("Accuracy Score for the algorithm=>{}%".format(round(accuracy_score(z_test,z_pred)*100),2))

y_pred= model.predict(X_test)
y_pred=np.round(y_pred)
np.set_printoptions(precision=2)
print(y_pred)

from sklearn.metrics import accuracy_score
print("Accuracy Score for the algorithm=>{}%".format(round(accuracy_score(y_test,y_pred)*100),2))